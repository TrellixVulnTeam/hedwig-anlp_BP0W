{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ftfy\n",
    "import textacy\n",
    "import csv\n",
    "from gensim.utils import simple_preprocess\n",
    "import unicodedata\n",
    "import swifter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sys\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "Lots of stuff here is embedding dependant. For instance, you should filter stop words when using word2vec, but you should not do that for glove. Glove also uses specific preprocessing procedure for twitter. Word2vec recommends stripping most punctuation. FastText replaces things like New York with new_york."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATASETS=Path('../../hedwig-data/datasets')\n",
    "STOP_WORDS = list(set(stopwords.words('english')))\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "ALPHABET = dict(map(lambda t: (t[1], t[0]),\n",
    "                    enumerate(list(\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:’’’/\\|_@#$%ˆ&*˜‘+-=<>()[]{}\"))))\n",
    "\n",
    "def get_stop_list(text_list, text_col=1, min_count=10):\n",
    "    word_freq = {}\n",
    "    remove = {}\n",
    "    for text in text_list:\n",
    "        for word in text.split():\n",
    "            if word in word_freq.keys():\n",
    "                word_freq[word] += 1\n",
    "            else:\n",
    "                word_freq[word] = 1\n",
    "    for k, v in word_freq.items():\n",
    "        if v < 3:\n",
    "            remove[k]=True\n",
    "\n",
    "    return remove\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \" {} \".format(hashtag_body.lower())\n",
    "    else:\n",
    "        result = \" \".join([\"\"] + [re.sub(r\"([A-Z])\",r\" \\1\", hashtag_body, flags=FLAGS)])\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" \"\n",
    "\n",
    "def tweet_preprocessing(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = text.replace(\"@ HASHTAG \", \"#\")\n",
    "    text = text.replace(\"@ USER \", \"<user> \")\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"#\\S+\", hashtag)\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = text.replace(\"@ URL\", \"<url>\")\n",
    "    text = text.replace(\" [ URL ] \", \"<url>\")\n",
    "    text = text.replace(\" [ USER ] \", \"<number>\")\n",
    "    text = text.replace(\" [ NUMBER ] \", \"<user>\")\n",
    "    text = text.replace(\" [ HASHTAG ] \", \"<hashtag>\")\n",
    "    text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "    \n",
    "    return text.lower()\n",
    "                 \n",
    "def is_whitespace(char):\n",
    "    \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
    "    # \\t, \\n, and \\r are technically contorl characters but we treat them\n",
    "    # as whitespace since they are generally considered as such.\n",
    "    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return True\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat == \"Zs\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_control(char):\n",
    "    \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
    "    # These are technically control characters but we count them as whitespace\n",
    "    # characters.\n",
    "    if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return False\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat.startswith(\"C\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
    "    output = []\n",
    "    for char in text:\n",
    "        cp = ord(char)\n",
    "        if cp == 0 or cp == 0xfffd or is_control(char):\n",
    "            continue\n",
    "        if is_whitespace(char):\n",
    "            output.append(\" \")\n",
    "        else:\n",
    "            output.append(char)\n",
    "    return \"\".join(output)\n",
    "\n",
    "def fix_contractions(text):\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Aa]re|[Cc]ould|[Dd]id|[Dd]oes|[Dd]o|[Hh]ad|[Hh]as|[Hh]ave|[Ii]s|[Mm]ight|[Mm]ust|[Ss]hould|[Ww]ere|[Ww]ould) n't\",\n",
    "        r\"\\1\\2 not\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) 'll\",\n",
    "        r\"\\1\\2 will\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(r\"(\\b)([Tt]here|[Hh]ere) 's\", r\"\\1\\2 is\", text)\n",
    "    text = re.sub(r\"(\\b)([Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) 're\", r\"\\1\\2 are\", text)\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Ii]|[Ss]hould|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Ww]ould|[Yy]ou) 've\",\n",
    "        r\"\\1\\2 have\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Yy]ou) 'd\",\n",
    "        r\"\\1\\2 would\",\n",
    "        text,\n",
    "    )\n",
    "    # non-standard\n",
    "    text = re.sub(r\"(\\b)([Cc]a) n't\", r\"\\1\\2n not\", text)\n",
    "    text = re.sub(r\"(\\b)([Ii]) 'm\", r\"\\1\\2 am\", text)\n",
    "    text = re.sub(r\"(\\b)([Ll]et) 's\", r\"\\1\\2 us\", text)\n",
    "    text = re.sub(r\"(\\b)([Ww]) on't\", r\"\\1\\2ill not\", text)\n",
    "    text = re.sub(r\"(\\b)([Ss]) han't\", r\"\\1\\2hall not\", text)\n",
    "    text = re.sub(r\"(\\b)([Yy])(?: 'all|a 'll)\", r\"\\1\\2ou all\", text)\n",
    "    #####################################################\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Aa]re|[Cc]ould|[Dd]id|[Dd]oes|[Dd]o|[Hh]ad|[Hh]as|[Hh]ave|[Ii]s|[Mm]ight|[Mm]ust|[Ss]hould|[Ww]ere|[Ww]ould) n ' t\",\n",
    "        r\"\\1\\2 not \",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) ' ll \",\n",
    "        r\"\\1\\2 will \",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(r\"(\\b)([Tt]here|[Hh]ere) ' s \", r\"\\1\\2 is\", text)\n",
    "    text = re.sub(r\"(\\b)([Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) ' re \", r\"\\1\\2 are\", text)\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Ii]|[Ss]hould|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Ww]ould|[Yy]ou) ' ve \",\n",
    "        r\"\\1\\2 have \",\n",
    "        text,\n",
    "    )\n",
    "\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Yy]ou) ' d \",\n",
    "        r\"\\1\\2 would \",\n",
    "        text,\n",
    "    )\n",
    "    # non-standard\n",
    "    text = re.sub(r\"(\\b)([Cc]a) n ' t \", r\"\\1\\2n not \", text)\n",
    "    text = re.sub(r\"(\\b)([Ii]) ' m \", r\"\\1\\2 am \", text)\n",
    "    text = re.sub(r\"(\\b)([Ll]et) ' s \", r\"\\1\\2 us \", text)\n",
    "    text = re.sub(r\"(\\b)([Ww]) on ' t \", r\"\\1\\2ill not \", text)\n",
    "    text = re.sub(r\"(\\b)([Ss]ha) n ' t \", r\"\\1\\2ll not \", text)\n",
    "    text = re.sub(r\"(\\b)([Yy])(?: ' all | a ' ll )\", r\"\\1\\2ou all \", text)\n",
    "    text=text.replace(\" 's \", \"'s \").replace(\" ' s \", \"'s \").replace(\" i ' m \", \" i am \")\n",
    "    return text\n",
    "    \n",
    "def soft_preprocess(df):\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(ftfy.fix_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(clean_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(\n",
    "        lambda x: x.replace(\n",
    "            '\"', \"\").replace(\"\\n\", \" \").replace(\"\\\\\",\"\").replace(\"`\",\"'\").replace(\"& amp ;\", \" and \"))\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(fix_contractions)\n",
    "    return df\n",
    "\n",
    "def df_to_hedwig_tsv(df, dsname, outfilename, num_labels_in_col, preprocess, is_twitter_process=True, stop_words=[],\n",
    "                     label_cols=[0], text_col=1):\n",
    "    def to_tsv(outfpath, labels, texts):\n",
    "        with open(outfpath, 'w', newline='') as tsvfile:\n",
    "            writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "            for label, text in zip(labels, texts):\n",
    "                if len(text.strip()) > 10:\n",
    "                    writer.writerow([label, text])\n",
    "    df = preprocess(df)\n",
    "    if is_twitter_process:\n",
    "        df.iloc[:,1]=df.iloc[:,1].swifter.apply(tweet_preprocessing)\n",
    "    df.iloc[:,1] = df.iloc[:,1].swifter.apply(lambda text: \" \".join(\n",
    "        [word for word in text.split() if word not in stop_words and len(word) < 15]).strip())\n",
    "    toremove=get_stop_list(df.iloc[:,1].tolist())\n",
    "    df.iloc[:,1] = df.iloc[:,1].swifter.apply(lambda text: \" \".join(\n",
    "        [word for word in text.split() if word not in toremove]).strip())\n",
    "    df.iloc[:,0] = df.swifter.apply(lambda row: ''.join([str(lbl) for lbl in row[label_cols]]), axis=1)\n",
    "    df = df.iloc[:,[0, 1]]\n",
    "    df.iloc[:,0]=df.iloc[:,0].astype('str')\n",
    "    df.iloc[:,0]=df.iloc[:,0].swifter.apply(\n",
    "        lambda x: x if len(x) == num_labels_in_col else ''.join(\n",
    "            ['0' for i in range(num_labels_in_col-len(x))]\n",
    "        )+str(x)\n",
    "    )\n",
    "    dspath=PATH_TO_DATASETS/dsname\n",
    "    outfpath = dspath/outfilename\n",
    "    df = df.sample(frac=1.0)\n",
    "    to_tsv(outfpath, df.iloc[:,0].tolist(), df.iloc[:,1].tolist())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/dev.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ac477b71da4f04a9a511334855be66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003ac87126bd4c4b9da367a656f1c32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f521d8fa166449f867e39aebfd5e021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e300b628acf847a292bcc136f7d690a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2472c6473e4f48b9200331d671f3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5690e0a93ea642e7984d27dd7e57b546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b94a15e3f240f29ac01b734dfda1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f811391d548142a3a62551a7a42f2da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedcf301f24c463aa6503a1f0d94940d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26199</th>\n",
       "      <td>0000</td>\n",
       "      <td>user way , briefly legend canterbury telling o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>1000</td>\n",
       "      <td>. thx much ! ! best part ( spotting new trends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21525</th>\n",
       "      <td>1011</td>\n",
       "      <td>still hurts . first page expect get better , ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43665</th>\n",
       "      <td>0100</td>\n",
       "      <td>believe sa bunso pa namin . &lt;user&gt; sometimes ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>1000</td>\n",
       "      <td>&lt;user&gt; . &lt;url&gt; / happiest little bookmark ! ##...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24612</th>\n",
       "      <td>1101</td>\n",
       "      <td>slowly becoming one fangirls wants draw time m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26095</th>\n",
       "      <td>1111</td>\n",
       "      <td>/ favorite things &lt;user&gt; &lt;user&gt; . hey , help u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39200</th>\n",
       "      <td>0001</td>\n",
       "      <td>heard one best movies last years &lt;url&gt; / revie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29330</th>\n",
       "      <td>0000</td>\n",
       "      <td>, verb &lt;url&gt; / &lt;user&gt; etsy highlight / / owl s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41960</th>\n",
       "      <td>0001</td>\n",
       "      <td>sauna . shower , cold water constantly always ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11250</th>\n",
       "      <td>0010</td>\n",
       "      <td>&lt;user&gt; part ? &lt;user&gt; hishon , holden , what's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37014</th>\n",
       "      <td>0011</td>\n",
       "      <td>least post update current status fill details ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42527</th>\n",
       "      <td>0001</td>\n",
       "      <td>even tend . ( much frustration nf buddies ) ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34871</th>\n",
       "      <td>0011</td>\n",
       "      <td>reckon &lt;user&gt; wicked . see , may tag along &lt;us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14109</th>\n",
       "      <td>0010</td>\n",
       "      <td>found regular meditation help acceptance / equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37855</th>\n",
       "      <td>0011</td>\n",
       "      <td>think saw crying watching interstellar . also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25669</th>\n",
       "      <td>1110</td>\n",
       "      <td>dr . always said cutter remember . oh . . gosh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20921</th>\n",
       "      <td>1011</td>\n",
       "      <td>set de fotos : gifsboom : static balloon cat ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46296</th>\n",
       "      <td>0111</td>\n",
       "      <td>profile interests hell freakin ! life one big ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19176</th>\n",
       "      <td>1011</td>\n",
       "      <td>go back plattsburgh right holidays . ridiculou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36952</th>\n",
       "      <td>0011</td>\n",
       "      <td>like average intj ? ? : confused : well yeah b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40265</th>\n",
       "      <td>0001</td>\n",
       "      <td>gonna pretend like see madonna suck soul drake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31250</th>\n",
       "      <td>0000</td>\n",
       "      <td>eilean place - &lt;url&gt; / &lt;user&gt; cute bracelets &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>1001</td>\n",
       "      <td>retaining part though ahaha &lt;user&gt; hmm alot st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11066</th>\n",
       "      <td>0010</td>\n",
       "      <td>rest seem correct &lt;smile&gt; feeling pretty good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1000</td>\n",
       "      <td>toilet . gonna burn . could u use tips effecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16498</th>\n",
       "      <td>1010</td>\n",
       "      <td>tried recommended . &lt;url&gt; / &lt;number&gt; &lt;user&gt; th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41438</th>\n",
       "      <td>0001</td>\n",
       "      <td>single one fears gays . think term incorrect s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>1001</td>\n",
       "      <td>user &lt;user&gt; &lt;user&gt; started challenging , witho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27819</th>\n",
       "      <td>0000</td>\n",
       "      <td>. &lt;url&gt; / keep intense dreams friendship group...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22933</th>\n",
       "      <td>0110</td>\n",
       "      <td>true aussie &lt;user&gt; &lt;elong&gt; . &lt;url&gt; / &lt;number&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31730</th>\n",
       "      <td>0000</td>\n",
       "      <td>little business knowledge wanna sell stuff wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14117</th>\n",
       "      <td>0010</td>\n",
       "      <td>? first say shut , quote another post . make m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13758</th>\n",
       "      <td>0010</td>\n",
       "      <td>! ! : &lt;user&gt; &lt;smile&gt; &lt;user&gt; give minutes dry g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7924</th>\n",
       "      <td>1001</td>\n",
       "      <td>already . funeral &lt;url&gt; / morocco gives perfec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8257</th>\n",
       "      <td>1001</td>\n",
       "      <td>people . days easier get multiple viewpoints ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14790</th>\n",
       "      <td>0010</td>\n",
       "      <td>kind . started running got running coach . wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32170</th>\n",
       "      <td>0000</td>\n",
       "      <td>tracking human trafficking criminals ? &lt;user&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18970</th>\n",
       "      <td>1010</td>\n",
       "      <td>last time help someone personal computer thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34050</th>\n",
       "      <td>0011</td>\n",
       "      <td>glory living lies never falling , rising every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10529</th>\n",
       "      <td>0010</td>\n",
       "      <td>pinterest pin . twitter sends email update ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39500</th>\n",
       "      <td>0001</td>\n",
       "      <td>today remembered like nahi 'll tomorrow witch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9591</th>\n",
       "      <td>1001</td>\n",
       "      <td>' well dogs pictures dogs . ( google know that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15606</th>\n",
       "      <td>1010</td>\n",
       "      <td>##… &lt;url&gt; / comfortable skin , beautiful . con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917</th>\n",
       "      <td>0010</td>\n",
       "      <td>binding ! looks like something resonated brian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9902</th>\n",
       "      <td>0010</td>\n",
       "      <td>ask xd muse pg : ♠ c ; &lt;url&gt; / photo : reborni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33237</th>\n",
       "      <td>0000</td>\n",
       "      <td>' hi ! thanks input ! yes , use advantage inna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20339</th>\n",
       "      <td>1011</td>\n",
       "      <td>ya . , know &lt;number&gt; minutes , know &lt;url&gt; / &lt;n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43869</th>\n",
       "      <td>0100</td>\n",
       "      <td>email showing . watching pot waiting water boi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9538</th>\n",
       "      <td>1001</td>\n",
       "      <td>pin pinned top sock wear take , pin back toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38939</th>\n",
       "      <td>0001</td>\n",
       "      <td>&gt; year ethnic casting &lt;user&gt; &lt;user&gt; might refl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>1000</td>\n",
       "      <td>&lt;number&gt; recipe - try pb + b protein pancakes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45271</th>\n",
       "      <td>0101</td>\n",
       "      <td>rapidly becoming new mlp / sonic fan base . wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14550</th>\n",
       "      <td>0010</td>\n",
       "      <td>live land ? mean ? asked twice ! : laughing : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31310</th>\n",
       "      <td>0000</td>\n",
       "      <td>different vibe . lots perspectives . caught &lt;u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30478</th>\n",
       "      <td>0000</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; like witch really feel like go o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21305</th>\n",
       "      <td>1011</td>\n",
       "      <td>needed time recover . . said issue wasnx&lt;numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43666</th>\n",
       "      <td>0100</td>\n",
       "      <td>&lt;user&gt; hahaha thank , lord . needed ##&lt;url&gt; / ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>1000</td>\n",
       "      <td>&lt;url&gt; / workers like donald joining raise fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>1000</td>\n",
       "      <td>frightened , dismayed , lord god wherever go ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46578 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "26199  0000  user way , briefly legend canterbury telling o...\n",
       "3296   1000  . thx much ! ! best part ( spotting new trends...\n",
       "21525  1011  still hurts . first page expect get better , ....\n",
       "43665  0100  believe sa bunso pa namin . <user> sometimes ,...\n",
       "4119   1000  <user> . <url> / happiest little bookmark ! ##...\n",
       "24612  1101  slowly becoming one fangirls wants draw time m...\n",
       "26095  1111  / favorite things <user> <user> . hey , help u...\n",
       "39200  0001  heard one best movies last years <url> / revie...\n",
       "29330  0000  , verb <url> / <user> etsy highlight / / owl s...\n",
       "41960  0001  sauna . shower , cold water constantly always ...\n",
       "11250  0010  <user> part ? <user> hishon , holden , what's ...\n",
       "37014  0011  least post update current status fill details ...\n",
       "42527  0001  even tend . ( much frustration nf buddies ) ea...\n",
       "34871  0011  reckon <user> wicked . see , may tag along <us...\n",
       "14109  0010  found regular meditation help acceptance / equ...\n",
       "37855  0011  think saw crying watching interstellar . also ...\n",
       "25669  1110  dr . always said cutter remember . oh . . gosh...\n",
       "20921  1011  set de fotos : gifsboom : static balloon cat ....\n",
       "46296  0111  profile interests hell freakin ! life one big ...\n",
       "19176  1011  go back plattsburgh right holidays . ridiculou...\n",
       "36952  0011  like average intj ? ? : confused : well yeah b...\n",
       "40265  0001  gonna pretend like see madonna suck soul drake...\n",
       "31250  0000  eilean place - <url> / <user> cute bracelets <...\n",
       "5554   1001  retaining part though ahaha <user> hmm alot st...\n",
       "11066  0010  rest seem correct <smile> feeling pretty good ...\n",
       "193    1000  toilet . gonna burn . could u use tips effecti...\n",
       "16498  1010  tried recommended . <url> / <number> <user> th...\n",
       "41438  0001  single one fears gays . think term incorrect s...\n",
       "4795   1001  user <user> <user> started challenging , witho...\n",
       "27819  0000  . <url> / keep intense dreams friendship group...\n",
       "...     ...                                                ...\n",
       "22933  0110  true aussie <user> <elong> . <url> / <number> ...\n",
       "31730  0000  little business knowledge wanna sell stuff wan...\n",
       "14117  0010  ? first say shut , quote another post . make m...\n",
       "13758  0010  ! ! : <user> <smile> <user> give minutes dry g...\n",
       "7924   1001  already . funeral <url> / morocco gives perfec...\n",
       "8257   1001  people . days easier get multiple viewpoints ,...\n",
       "14790  0010  kind . started running got running coach . wan...\n",
       "32170  0000  tracking human trafficking criminals ? <user> ...\n",
       "18970  1010  last time help someone personal computer thing...\n",
       "34050  0011  glory living lies never falling , rising every...\n",
       "10529  0010  pinterest pin . twitter sends email update ter...\n",
       "39500  0001  today remembered like nahi 'll tomorrow witch ...\n",
       "9591   1001  ' well dogs pictures dogs . ( google know that...\n",
       "15606  1010  ##… <url> / comfortable skin , beautiful . con...\n",
       "9917   0010  binding ! looks like something resonated brian...\n",
       "9902   0010  ask xd muse pg : ♠ c ; <url> / photo : reborni...\n",
       "33237  0000  ' hi ! thanks input ! yes , use advantage inna...\n",
       "20339  1011  ya . , know <number> minutes , know <url> / <n...\n",
       "43869  0100  email showing . watching pot waiting water boi...\n",
       "9538   1001  pin pinned top sock wear take , pin back toget...\n",
       "38939  0001  > year ethnic casting <user> <user> might refl...\n",
       "3230   1000  <number> recipe - try pb + b protein pancakes ...\n",
       "45271  0101  rapidly becoming new mlp / sonic fan base . wa...\n",
       "14550  0010  live land ? mean ? asked twice ! : laughing : ...\n",
       "31310  0000  different vibe . lots perspectives . caught <u...\n",
       "30478  0000  <user> <user> like witch really feel like go o...\n",
       "21305  1011  needed time recover . . said issue wasnx<numbe...\n",
       "43666  0100  <user> hahaha thank , lord . needed ##<url> / ...\n",
       "2658   1000  <url> / workers like donald joining raise fami...\n",
       "2325   1000  frightened , dismayed , lord god wherever go ....\n",
       "\n",
       "[46578 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/dev.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='dev.tsv', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True)\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d566d53e2dd4ae788d7ec51218142de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d613e9ae4b54fa4a0cbb8439b1c1ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad05daaa986e421884b4539be48d1000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e2c37e4b2b418b92a896304d67f435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d06921073640b3a7771b7cec8a5171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c0098628374891b5e193b964821735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd0ac3be3a94625801a33cf2cc851f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b40fd331a9426e9dfe2835b3d01be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642e988abfa14759a9b8935baa59cf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/test.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='test.tsv', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f579c97bf040b5bc5ceb52e207ef29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd07001330714eb28aa679197db6b554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/swifter/swifter.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# try to vectorize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0msamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-655167851f73>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0xfffd\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ord() expected a character, but string of length 2290 found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6260721f4abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../hedwig-data/datasets/MBTI/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='train.tsv', num_labels_in_col=4,\n\u001b[0;32m----> 3\u001b[0;31m                      preprocess=soft_preprocess, is_twitter_process=True, stop_words=STOP_WORDS)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-655167851f73>\u001b[0m in \u001b[0;36mdf_to_hedwig_tsv\u001b[0;34m(df, dsname, outfilename, num_labels_in_col, preprocess, is_twitter_process, stop_words, label_cols, text_col)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_twitter_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswifter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_preprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-655167851f73>\u001b[0m in \u001b[0;36msoft_preprocess\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoft_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswifter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftfy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswifter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     df.iloc[:,1]=df.iloc[:,1].swifter.apply(\n\u001b[1;32m    170\u001b[0m         lambda x: x.replace(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/swifter/swifter.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Pandas Apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;31m# Close bar and return pandas calculation result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-655167851f73>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0xfffd\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_whitespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/train.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='train.tsv', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
