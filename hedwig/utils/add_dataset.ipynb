{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ftfy\n",
    "import textacy\n",
    "import csv\n",
    "from gensim.utils import simple_preprocess\n",
    "import unicodedata\n",
    "import swifter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sys\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "Lots of stuff here is embedding dependant. For instance, you should filter stop words when using word2vec, but you should not do that for glove. Glove also uses specific preprocessing procedure for twitter. Word2vec recommends stripping most punctuation. FastText replaces things like New York with new_york."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATASETS=Path('../../hedwig-data/datasets')\n",
    "STOP_WORDS = list(set(stopwords.words('english')))\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \" {} \".format(hashtag_body.lower())\n",
    "    else:\n",
    "        result = \" \".join([\"\"] + [re.sub(r\"([A-Z])\",r\" \\1\", hashtag_body, flags=FLAGS)])\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" \"\n",
    "\n",
    "def tweet_preprocessing(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = text.replace(\"@ HASHTAG \", \"#\")\n",
    "    text = text.replace(\"@ USER \", \"<user> \")\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"#\\S+\", hashtag)\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = text.replace(\"@ URL\", \"<url>\")\n",
    "    text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "    \n",
    "    return text.lower()\n",
    "                 \n",
    "def is_whitespace(char):\n",
    "    \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
    "    # \\t, \\n, and \\r are technically contorl characters but we treat them\n",
    "    # as whitespace since they are generally considered as such.\n",
    "    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return True\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat == \"Zs\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_control(char):\n",
    "    \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
    "    # These are technically control characters but we count them as whitespace\n",
    "    # characters.\n",
    "    if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return False\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat.startswith(\"C\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
    "    output = []\n",
    "    for char in text:\n",
    "        cp = ord(char)\n",
    "        if cp == 0 or cp == 0xfffd or is_control(char):\n",
    "            continue\n",
    "        if is_whitespace(char):\n",
    "            output.append(\" \")\n",
    "        else:\n",
    "            output.append(char)\n",
    "    return \"\".join(output)\n",
    "\n",
    "def fix_contractions(text):\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Aa]re|[Cc]ould|[Dd]id|[Dd]oes|[Dd]o|[Hh]ad|[Hh]as|[Hh]ave|[Ii]s|[Mm]ight|[Mm]ust|[Ss]hould|[Ww]ere|[Ww]ould) n't\",\n",
    "        r\"\\1\\2 not\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) 'll\",\n",
    "        r\"\\1\\2 will\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(r\"(\\b)([Tt]here|[Hh]ere) 's\", r\"\\1\\2 is\", text)\n",
    "    text = re.sub(r\"(\\b)([Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) 're\", r\"\\1\\2 are\", text)\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Ii]|[Ss]hould|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Ww]ould|[Yy]ou) 've\",\n",
    "        r\"\\1\\2 have\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Yy]ou) 'd\",\n",
    "        r\"\\1\\2 would\",\n",
    "        text,\n",
    "    )\n",
    "    # non-standard\n",
    "    text = re.sub(r\"(\\b)([Cc]a) n't\", r\"\\1\\2n not\", text)\n",
    "    text = re.sub(r\"(\\b)([Ii]) 'm\", r\"\\1\\2 am\", text)\n",
    "    text = re.sub(r\"(\\b)([Ll]et) 's\", r\"\\1\\2 us\", text)\n",
    "    text = re.sub(r\"(\\b)([Ww]) on't\", r\"\\1\\2ill not\", text)\n",
    "    text = re.sub(r\"(\\b)([Ss]) han't\", r\"\\1\\2hall not\", text)\n",
    "    text = re.sub(r\"(\\b)([Yy])(?: 'all|a 'll)\", r\"\\1\\2ou all\", text)\n",
    "    #####################################################\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Aa]re|[Cc]ould|[Dd]id|[Dd]oes|[Dd]o|[Hh]ad|[Hh]as|[Hh]ave|[Ii]s|[Mm]ight|[Mm]ust|[Ss]hould|[Ww]ere|[Ww]ould) n ' t\",\n",
    "        r\"\\1\\2 not \",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) ' ll \",\n",
    "        r\"\\1\\2 will \",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(r\"(\\b)([Tt]here|[Hh]ere) ' s \", r\"\\1\\2 is\", text)\n",
    "    text = re.sub(r\"(\\b)([Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) ' re \", r\"\\1\\2 are\", text)\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Ii]|[Ss]hould|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Ww]ould|[Yy]ou) ' ve \",\n",
    "        r\"\\1\\2 have \",\n",
    "        text,\n",
    "    )\n",
    "\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Yy]ou) ' d \",\n",
    "        r\"\\1\\2 would \",\n",
    "        text,\n",
    "    )\n",
    "    # non-standard\n",
    "    text = re.sub(r\"(\\b)([Cc]a) n ' t \", r\"\\1\\2n not \", text)\n",
    "    text = re.sub(r\"(\\b)([Ii]) ' m \", r\"\\1\\2 am \", text)\n",
    "    text = re.sub(r\"(\\b)([Ll]et) ' s \", r\"\\1\\2 us \", text)\n",
    "    text = re.sub(r\"(\\b)([Ww]) on ' t \", r\"\\1\\2ill not \", text)\n",
    "    text = re.sub(r\"(\\b)([Ss]ha) n ' t \", r\"\\1\\2ll not \", text)\n",
    "    text = re.sub(r\"(\\b)([Yy])(?: ' all | a ' ll )\", r\"\\1\\2ou all \", text)\n",
    "    text=text.replace(\" 's \", \"'s \").replace(\" ' s \", \"'s \").replace(\" i ' m \", \" i'm \")\n",
    "    return text\n",
    "\n",
    "def hard_preprocess(df):\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(ftfy.fix_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(clean_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(lambda x: x.replace('\"', '').replace(\"\\n\", \" \").replace(\"\\\\\",\"\"))\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(lambda text: textacy.preprocess_text(\n",
    "        text, no_currency_symbols=True,no_urls=True,no_emails=True,no_phone_numbers=True,no_numbers=True))\n",
    "    df.iloc[:,1] = df.iloc[:,1].apply(lambda x: x.replace(\"`\",\"'\").replace(\n",
    "                                        \"& amp ;\", \" and \").replace(\n",
    "                                        \"@ USER\", \"[USER]\").replace(\n",
    "                                        \"@ URL\", \"[URL]\").replace(\n",
    "                                        \"@ HASHTAG\", \"[HASHTAG]\").replace(\n",
    "                                        \"*NUMBER*\", \"[NUMBER]\")\n",
    "                                     )\n",
    "    df.iloc[:,1]=df.iloc[:,1].apply(fix_contractions)\n",
    "    return df\n",
    "\n",
    "def soft_preprocess(df):\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(ftfy.fix_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(clean_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(\n",
    "        lambda x: x.replace('\"', \"\").replace(\"\\n\", \" \").replace(\"\\\\\",\"\").replace(\"`\",\"'\"))\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(fix_contractions)\n",
    "    return df\n",
    "\n",
    "def df_to_hedwig_tsv(df, dsname, outfilename, num_labels_in_col, preprocess, is_twitter_process=True, stop_words=[],\n",
    "                     label_cols=[0], text_col=1):\n",
    "    def to_tsv(outfpath, labels, texts):\n",
    "        with open(outfpath, 'w', newline='') as tsvfile:\n",
    "            writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "            for label, text in zip(labels, texts):\n",
    "                writer.writerow([label, text])\n",
    "    df = preprocess(df)\n",
    "    if is_twitter_process:\n",
    "        df.iloc[:,1]=df.iloc[:,1].swifter.apply(tweet_preprocessing)\n",
    "    df.iloc[:,1] = df.iloc[:,1].swifter.apply(lambda text: \" \".join(\n",
    "        [word for word in text.split() if word not in stop_words and len(word) < 15]).strip())    \n",
    "    df.iloc[:,0] = df.swifter.apply(lambda row: ''.join([str(lbl) for lbl in row[label_cols]]), axis=1)\n",
    "    df = df.iloc[:,[0, 1]]\n",
    "    df.iloc[:,0]=df.iloc[:,0].astype('str')\n",
    "    df.iloc[:,0]=df.iloc[:,0].swifter.apply(\n",
    "        lambda x: x if len(x) == num_labels_in_col else ''.join(\n",
    "            ['0' for i in range(num_labels_in_col-len(x))]\n",
    "        )+str(x)\n",
    "    )\n",
    "    dspath=PATH_TO_DATASETS/dsname\n",
    "    outfpath = dspath/outfilename\n",
    "    df = df.sample(frac=1.0)\n",
    "    to_tsv(outfpath, df.iloc[:,0].tolist(), df.iloc[:,1].tolist())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045f65e44c5742afbea9001f1fedb4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e7251bd59d49abbd38f940235466ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0f4fd89dfa4a62a9450d0f49a06e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d27671857104feaabc636a0c9cb06ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6889189588534799afacb1e02654c30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e88146b6e945908915aa0ff23045c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d328125a2e04540b9b421b3c0c8c121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3acb15bb1346e580a4c50912f7dc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/dev.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='dev.tsv', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc85cd264bf74f46b7d6245c0790d88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01faed9260fa4491805fa3784ac14032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77869ef2ec0a4d349aed9639496fcd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a180591fbc0d49f4b7130978839ae47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7a1036851d48e882082e72391ce245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651cf99a0a404fe1aa643e1187084965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd6365131394b93a0d2771c0e2da2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d26de25f6b4116a79628e8984f4bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/test.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='test.tsv.stop', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dec4bba06044f898eaf43b754e5c97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d8f969157b482d99d4a91eecdbf687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9b551990e6464a8a7b0c99238380b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f0d4989c4e43b3a97a497d42c21a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca2fe53ed034604b86071d436566abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aadfed6ceea4d3086777780379c344c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45669e496a7a43739c202c722c1f68e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f64944778924864b4cefe19cf23dfe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/train.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='train.tsv.stop', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
