{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ftfy\n",
    "import textacy\n",
    "import csv\n",
    "from gensim.utils import simple_preprocess\n",
    "import unicodedata\n",
    "import swifter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sys\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "Lots of stuff here is embedding dependant. For instance, you should filter stop words when using word2vec, but you should not do that for glove. Glove also uses specific preprocessing procedure for twitter. Word2vec recommends stripping most punctuation. FastText replaces things like New York with new_york."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATASETS=Path('../../hedwig-data/datasets')\n",
    "STOP_WORDS = list(set(stopwords.words('english')))\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "ALPHABET = dict(map(lambda t: (t[1], t[0]),\n",
    "                    enumerate(list(\"\"\"abcdefghijklmnopqrstuvwxyz.!?'<>\"\"\"))))\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \" {} \".format(hashtag_body.lower())\n",
    "    else:\n",
    "        result = \" \".join([\"\"] + [re.sub(r\"([A-Z])\",r\" \\1\", hashtag_body, flags=FLAGS)])\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" \"\n",
    "\n",
    "def tweet_preprocessing(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = text.replace(\"@ HASHTAG \", \"#\")\n",
    "    text = text.replace(\"@ USER \", \"<user> \")\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"#\\S+\", hashtag)\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = text.replace(\"@ URL\", \"<url>\")\n",
    "    text = text.replace(\" [ URL ] \", \"<url>\")\n",
    "    text = text.replace(\" [ USER ] \", \"<number>\")\n",
    "    text = text.replace(\" [ NUMBER ] \", \"<user>\")\n",
    "    text = text.replace(\" [ HASHTAG ] \", \"<hashtag>\")\n",
    "    text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "    \n",
    "    return text.lower()\n",
    "                 \n",
    "def is_whitespace(char):\n",
    "    \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
    "    # \\t, \\n, and \\r are technically contorl characters but we treat them\n",
    "    # as whitespace since they are generally considered as such.\n",
    "    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return True\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat == \"Zs\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_control(char):\n",
    "    \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
    "    # These are technically control characters but we count them as whitespace\n",
    "    # characters.\n",
    "    if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return False\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat.startswith(\"C\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
    "    output = []\n",
    "    for char in text:\n",
    "        cp = ord(char)\n",
    "        if cp == 0 or cp == 0xfffd or is_control(char):\n",
    "            continue\n",
    "        if is_whitespace(char):\n",
    "            output.append(\" \")\n",
    "        else:\n",
    "            output.append(char)\n",
    "    return \"\".join(output)\n",
    "\n",
    "def fix_contractions(text):\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Aa]re|[Cc]ould|[Dd]id|[Dd]oes|[Dd]o|[Hh]ad|[Hh]as|[Hh]ave|[Ii]s|[Mm]ight|[Mm]ust|[Ss]hould|[Ww]ere|[Ww]ould) n't\",\n",
    "        r\"\\1\\2 not\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) 'll\",\n",
    "        r\"\\1\\2 will\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(r\"(\\b)([Tt]here|[Hh]ere) 's\", r\"\\1\\2 is\", text)\n",
    "    text = re.sub(r\"(\\b)([Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) 're\", r\"\\1\\2 are\", text)\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Ii]|[Ss]hould|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Ww]ould|[Yy]ou) 've\",\n",
    "        r\"\\1\\2 have\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Yy]ou) 'd\",\n",
    "        r\"\\1\\2 would\",\n",
    "        text,\n",
    "    )\n",
    "    # non-standard\n",
    "    text = re.sub(r\"(\\b)([Cc]a) n't\", r\"\\1\\2n not\", text)\n",
    "    text = re.sub(r\"(\\b)([Ii]) 'm\", r\"\\1\\2 am\", text)\n",
    "    text = re.sub(r\"(\\b)([Ll]et) 's\", r\"\\1\\2 us\", text)\n",
    "    text = re.sub(r\"(\\b)([Ww]) on't\", r\"\\1\\2ill not\", text)\n",
    "    text = re.sub(r\"(\\b)([Ss]) han't\", r\"\\1\\2hall not\", text)\n",
    "    text = re.sub(r\"(\\b)([Yy])(?: 'all|a 'll)\", r\"\\1\\2ou all\", text)\n",
    "    #####################################################\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Aa]re|[Cc]ould|[Dd]id|[Dd]oes|[Dd]o|[Hh]ad|[Hh]as|[Hh]ave|[Ii]s|[Mm]ight|[Mm]ust|[Ss]hould|[Ww]ere|[Ww]ould) n ' t\",\n",
    "        r\"\\1\\2 not \",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) ' ll \",\n",
    "        r\"\\1\\2 will \",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(r\"(\\b)([Tt]here|[Hh]ere) ' s \", r\"\\1\\2 is\", text)\n",
    "    text = re.sub(r\"(\\b)([Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) ' re \", r\"\\1\\2 are\", text)\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Ii]|[Ss]hould|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Ww]ould|[Yy]ou) ' ve \",\n",
    "        r\"\\1\\2 have \",\n",
    "        text,\n",
    "    )\n",
    "\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Yy]ou) ' d \",\n",
    "        r\"\\1\\2 would \",\n",
    "        text,\n",
    "    )\n",
    "    # non-standard\n",
    "    text = re.sub(r\"(\\b)([Cc]a) n ' t \", r\"\\1\\2n not \", text)\n",
    "    text = re.sub(r\"(\\b)([Ii]) ' m \", r\"\\1\\2 am \", text)\n",
    "    text = re.sub(r\"(\\b)([Ll]et) ' s \", r\"\\1\\2 us \", text)\n",
    "    text = re.sub(r\"(\\b)([Ww]) on ' t \", r\"\\1\\2ill not \", text)\n",
    "    text = re.sub(r\"(\\b)([Ss]ha) n ' t \", r\"\\1\\2ll not \", text)\n",
    "    text = re.sub(r\"(\\b)([Yy])(?: ' all | a ' ll )\", r\"\\1\\2ou all \", text)\n",
    "    text=text.replace(\" 's \", \"'s \").replace(\" ' s \", \"'s \").replace(\" i ' m \", \" i'm \")\n",
    "    return text\n",
    "\n",
    "def hard_preprocess(df):\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(ftfy.fix_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(clean_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(lambda x: x.replace('\"', '').replace(\"\\n\", \" \").replace(\"\\\\\",\"\"))\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(lambda text: textacy.preprocess_text(\n",
    "        text, no_currency_symbols=True,no_urls=True,no_emails=True,no_phone_numbers=True,no_numbers=True))\n",
    "    df.iloc[:,1] = df.iloc[:,1].apply(lambda x: x.replace(\"`\",\"'\").replace(\n",
    "                                        \"& amp ;\", \" and \").replace(\n",
    "                                        \"@ USER\", \"[USER]\").replace(\n",
    "                                        \"@ URL\", \"[URL]\").replace(\n",
    "                                        \"@ HASHTAG\", \"[HASHTAG]\").replace(\n",
    "                                        \"*NUMBER*\", \"[NUMBER]\")\n",
    "                                     )\n",
    "    df.iloc[:,1]=df.iloc[:,1].apply(fix_contractions)\n",
    "    return df\n",
    "\n",
    "def char_quantize(string, max_length=1000):\n",
    "    identity = np.identity(len(ALPHABET))\n",
    "    return len(np.array([identity[ALPHABET[char]] for char in list(string.lower()) if char in ALPHABET],\n",
    "                        dtype=np.float32))\n",
    "    \n",
    "def soft_preprocess(df):\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(ftfy.fix_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(clean_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(\n",
    "        lambda x: x.replace('\"', \"\").replace(\"\\n\", \" \").replace(\"\\\\\",\"\").replace(\"`\",\"'\"))\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(fix_contractions)\n",
    "    return df\n",
    "\n",
    "def df_to_hedwig_tsv(df, dsname, outfilename, num_labels_in_col, preprocess, is_twitter_process=True, stop_words=[],\n",
    "                     label_cols=[0], text_col=1):\n",
    "    def to_tsv(outfpath, labels, texts):\n",
    "        with open(outfpath, 'w', newline='') as tsvfile:\n",
    "            writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "            for label, text in zip(labels, texts):\n",
    "                if char_quantize(text) > 10:\n",
    "                    writer.writerow([label, text])\n",
    "    df = preprocess(df)\n",
    "    if is_twitter_process:\n",
    "        df.iloc[:,1]=df.iloc[:,1].swifter.apply(tweet_preprocessing)\n",
    "    df.iloc[:,1] = df.iloc[:,1].swifter.apply(lambda text: \" \".join(\n",
    "        [word for word in text.split() if word not in stop_words and len(word) < 15]).strip())    \n",
    "    df.iloc[:,0] = df.swifter.apply(lambda row: ''.join([str(lbl) for lbl in row[label_cols]]), axis=1)\n",
    "    df = df.iloc[:,[0, 1]]\n",
    "    df.iloc[:,0]=df.iloc[:,0].astype('str')\n",
    "    df.iloc[:,0]=df.iloc[:,0].swifter.apply(\n",
    "        lambda x: x if len(x) == num_labels_in_col else ''.join(\n",
    "            ['0' for i in range(num_labels_in_col-len(x))]\n",
    "        )+str(x)\n",
    "    )\n",
    "    dspath=PATH_TO_DATASETS/dsname\n",
    "    outfpath = dspath/outfilename\n",
    "    df = df.sample(frac=1.0)\n",
    "    to_tsv(outfpath, df.iloc[:,0].tolist(), df.iloc[:,1].tolist())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1790dac9a9ea48c08613ce7231a95437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc5fc526cfc4df1b88bb68e455e6c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80540e29aa8c4ed7a9d65d79c1f53a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d61aa10709a48fab25c461ad1066c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba9a89afc5049a7a102c88b5bb31f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a132413c6a4c40058849a03a3740332a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7db7f0540d461cbb7abd86fd548ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd0373f05aa46d787900fe14c09de6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/dev.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='dev.tsv', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True, stop_words=STOP_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a041b64d9eb4094a4c5c6772f885248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3e1e4d1668468abc36e1db783d4284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15047e05f60e4145a79e840918c92960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ea76afd82440f4a04f6451c70c6e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750ccfc4746844a78a8cf77f59576a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503637231fc64e9ea314754c1be27b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54e1e747b5b45d0adbfa28ffc5f744b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb255dad8d694983a0131be0cd37578d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/test.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='test.stop.tsv', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True, stop_words=STOP_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4595309f72f4b39b4b35ef0bd76f970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4a58154bc84afbb10b7d3f0a2beffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82ce62d121e4278b517ef0137b68822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6191d17402564d45b36dfa4e1d30d3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582db99b09944f859174eeb5bc7b8c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4657b21f62364c84b9c41ea2342ac71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4751948b0dd040829e47faa084f3380d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eab65769608400eb67c1b4297426ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/train.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='train.stop.tsv', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True, stop_words=STOP_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
