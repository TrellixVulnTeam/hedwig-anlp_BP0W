{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ftfy\n",
    "import textacy\n",
    "import csv\n",
    "from gensim.utils import simple_preprocess\n",
    "import unicodedata\n",
    "import swifter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sys\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "Lots of stuff here is embedding dependant. For instance, you should filter stop words when using word2vec, but you should not do that for glove. Glove also uses specific preprocessing procedure for twitter. Word2vec recommends stripping most punctuation. FastText replaces things like New York with new_york."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATASETS=Path('../../hedwig-data/datasets')\n",
    "STOP_WORDS = list(set(stopwords.words('english')))\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \" {} \".format(hashtag_body.lower())\n",
    "    else:\n",
    "        result = \" \".join([\"\"] + [re.sub(r\"([A-Z])\",r\" \\1\", hashtag_body, flags=FLAGS)])\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" \"\n",
    "\n",
    "def tweet_preprocessing(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = text.replace(\"@ HASHTAG \", \"#\")\n",
    "    text = text.replace(\"@ USER \", \"<user> \")\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"#\\S+\", hashtag)\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = text.replace(\"@ URL\", \"<url>\")\n",
    "    text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "    \n",
    "    return text.lower()\n",
    "                 \n",
    "def is_whitespace(char):\n",
    "    \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
    "    # \\t, \\n, and \\r are technically contorl characters but we treat them\n",
    "    # as whitespace since they are generally considered as such.\n",
    "    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return True\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat == \"Zs\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_control(char):\n",
    "    \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
    "    # These are technically control characters but we count them as whitespace\n",
    "    # characters.\n",
    "    if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return False\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat.startswith(\"C\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
    "    output = []\n",
    "    for char in text:\n",
    "        cp = ord(char)\n",
    "        if cp == 0 or cp == 0xfffd or is_control(char):\n",
    "            continue\n",
    "        if is_whitespace(char):\n",
    "            output.append(\" \")\n",
    "        else:\n",
    "            output.append(char)\n",
    "    return \"\".join(output)\n",
    "\n",
    "def fix_contractions(text):\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Aa]re|[Cc]ould|[Dd]id|[Dd]oes|[Dd]o|[Hh]ad|[Hh]as|[Hh]ave|[Ii]s|[Mm]ight|[Mm]ust|[Ss]hould|[Ww]ere|[Ww]ould) n't\",\n",
    "        r\"\\1\\2 not\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) 'll\",\n",
    "        r\"\\1\\2 will\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(r\"(\\b)([Tt]here|[Hh]ere) 's\", r\"\\1\\2 is\", text)\n",
    "    text = re.sub(r\"(\\b)([Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) 're\", r\"\\1\\2 are\", text)\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Ii]|[Ss]hould|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Ww]ould|[Yy]ou) 've\",\n",
    "        r\"\\1\\2 have\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Yy]ou) 'd\",\n",
    "        r\"\\1\\2 would\",\n",
    "        text,\n",
    "    )\n",
    "    # non-standard\n",
    "    text = re.sub(r\"(\\b)([Cc]a) n't\", r\"\\1\\2n not\", text)\n",
    "    text = re.sub(r\"(\\b)([Ii]) 'm\", r\"\\1\\2 am\", text)\n",
    "    text = re.sub(r\"(\\b)([Ll]et) 's\", r\"\\1\\2 us\", text)\n",
    "    text = re.sub(r\"(\\b)([Ww]) on't\", r\"\\1\\2ill not\", text)\n",
    "    text = re.sub(r\"(\\b)([Ss]) han't\", r\"\\1\\2hall not\", text)\n",
    "    text = re.sub(r\"(\\b)([Yy])(?: 'all|a 'll)\", r\"\\1\\2ou all\", text)\n",
    "    #####################################################\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Aa]re|[Cc]ould|[Dd]id|[Dd]oes|[Dd]o|[Hh]ad|[Hh]as|[Hh]ave|[Ii]s|[Mm]ight|[Mm]ust|[Ss]hould|[Ww]ere|[Ww]ould) n ' t\",\n",
    "        r\"\\1\\2 not \",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) ' ll \",\n",
    "        r\"\\1\\2 will \",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(r\"(\\b)([Tt]here|[Hh]ere) ' s \", r\"\\1\\2 is\", text)\n",
    "    text = re.sub(r\"(\\b)([Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou) ' re \", r\"\\1\\2 are\", text)\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Ii]|[Ss]hould|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Ww]ould|[Yy]ou) ' ve \",\n",
    "        r\"\\1\\2 have \",\n",
    "        text,\n",
    "    )\n",
    "\n",
    "    text = re.sub(\n",
    "        r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Yy]ou) ' d \",\n",
    "        r\"\\1\\2 would \",\n",
    "        text,\n",
    "    )\n",
    "    # non-standard\n",
    "    text = re.sub(r\"(\\b)([Cc]a) n ' t \", r\"\\1\\2n not \", text)\n",
    "    text = re.sub(r\"(\\b)([Ii]) ' m \", r\"\\1\\2 am \", text)\n",
    "    text = re.sub(r\"(\\b)([Ll]et) ' s \", r\"\\1\\2 us \", text)\n",
    "    text = re.sub(r\"(\\b)([Ww]) on ' t \", r\"\\1\\2ill not \", text)\n",
    "    text = re.sub(r\"(\\b)([Ss]ha) n ' t \", r\"\\1\\2ll not \", text)\n",
    "    text = re.sub(r\"(\\b)([Yy])(?: ' all | a ' ll )\", r\"\\1\\2ou all \", text)\n",
    "    text=text.replace(\" 's \", \"'s \").replace(\" ' s \", \"'s \").replace(\" i ' m \", \" i'm \")\n",
    "    return text\n",
    "\n",
    "def hard_preprocess(df):\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(ftfy.fix_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(clean_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(lambda x: x.replace('\"', '').replace(\"\\n\", \" \").replace(\"\\\\\",\"\"))\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(lambda text: textacy.preprocess_text(\n",
    "        text, no_currency_symbols=True,no_urls=True,no_emails=True,no_phone_numbers=True,no_numbers=True))\n",
    "    df.iloc[:,1] = df.iloc[:,1].apply(lambda x: x.replace(\"`\",\"'\").replace(\n",
    "                                        \"& amp ;\", \" and \").replace(\n",
    "                                        \"@ USER\", \"[USER]\").replace(\n",
    "                                        \"@ URL\", \"[URL]\").replace(\n",
    "                                        \"@ HASHTAG\", \"[HASHTAG]\").replace(\n",
    "                                        \"*NUMBER*\", \"[NUMBER]\")\n",
    "                                     )\n",
    "    df.iloc[:,1]=df.iloc[:,1].apply(fix_contractions)\n",
    "    return df\n",
    "\n",
    "def soft_preprocess(df):\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(ftfy.fix_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(clean_text)\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(\n",
    "        lambda x: x.replace('\"', \"\").replace(\"\\n\", \" \").replace(\"\\\\\",\"\").replace(\"`\",\"'\"))\n",
    "    df.iloc[:,1]=df.iloc[:,1].swifter.apply(fix_contractions)\n",
    "    return df\n",
    "\n",
    "def df_to_hedwig_tsv(df, dsname, outfilename, num_labels_in_col, preprocess, is_twitter_process=True, stop_words=[],\n",
    "                     label_cols=[0], text_col=1):\n",
    "    def to_tsv(outfpath, labels, texts):\n",
    "        with open(outfpath, 'w', newline='') as tsvfile:\n",
    "            writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "            for label, text in zip(labels, texts):\n",
    "                writer.writerow([label, text])\n",
    "    df = preprocess(df)\n",
    "    if is_twitter_process:\n",
    "        df.iloc[:,1]=df.iloc[:,1].swifter.apply(tweet_preprocessing)\n",
    "    df.iloc[:,1] = df.iloc[:,1].swifter.apply(lambda text: \" \".join(\n",
    "        [word for word in text.split() if word not in stop_words and len(word) < 15]).strip())    \n",
    "    df.iloc[:,0] = df.swifter.apply(lambda row: ''.join([str(lbl) for lbl in row[label_cols]]), axis=1)\n",
    "    df = df.iloc[:,[0, 1]]\n",
    "    df.iloc[:,0]=df.iloc[:,0].astype('str')\n",
    "    df.iloc[:,0]=df.iloc[:,0].swifter.apply(\n",
    "        lambda x: x if len(x) == num_labels_in_col else ''.join(\n",
    "            ['0' for i in range(num_labels_in_col-len(x))]\n",
    "        )+str(x)\n",
    "    )\n",
    "    dspath=PATH_TO_DATASETS/dsname\n",
    "    outfpath = dspath/outfilename\n",
    "    df = df.sample(frac=1.0)\n",
    "    to_tsv(outfpath, df.iloc[:,0].tolist(), df.iloc[:,1].tolist())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d6ca6148764faba47696500186c3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47add64585984f408be06838057132ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf62126dba9840f2a99ea4328285fb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775839bab4e746d3a235c78a8704ffe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8160868efa73455b8dfaaf85a5923426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f80156f33ea49c183bc5edd9be54657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a5f4dea9ae440fa763110df9e3529b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1592e084944dc3b2a702bd036f6ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=46578, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/dev.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='dev.stop.tsv', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103eafc082424a18929e7a6f253a5a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc4d79eb9fb4bd1b87b4928745f7464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6128f4b0f3d470cafce1d1863fc737f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6d6e3cdf424c978aa2fadbcfc54b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c30626f28b4217ad28d53aaa5fe9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbb563ddae142b5b0f5c311d40c6084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49387a028e104a889c66863f07eff36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e54e7a4c11417f8ee37d630e8df080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=150214, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/test.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='test.stop.tsv', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89be83855f845c99a4834179986a917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24b7735cde241158bfd2a6d8045cc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ddd623d6d34078b533a5b152a46e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82fe4e1cfd0426d85723a992c127386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ecd4ae372d40ad994d98594a757ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657f12e3df1d496b89c5b2a467987e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248995f284cb4904873cd2ca4145d8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e76f73b9d642ccbb34b50c8b5d2490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=600857, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../../hedwig-data/datasets/MBTI/train.csv')\n",
    "tdf=df_to_hedwig_tsv(df, dsname=\"MBTI\", outfilename='train.stop.tsv', num_labels_in_col=4,\n",
    "                     preprocess=soft_preprocess, is_twitter_process=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
